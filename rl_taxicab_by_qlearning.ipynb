{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91301e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "import matplotlib as mpl\n",
    "import random\n",
    "\n",
    "%matplotlib inline\n",
    "# %matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b963043c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Drive():\n",
    "    def __init__(self, render_mode='rgb_array', lr=8e-1, df=5e-1, epoches=1000, max_move=100, eps=0.7, qtable=None):\n",
    "        self.env = gym.make('Taxi-v3', render_mode=render_mode).env\n",
    "        self.active_state = self.env.reset()[0]\n",
    "        self.state_space = self.env.observation_space.n\n",
    "        self.action_space = self.env.action_space.n\n",
    "        self.lr = lr\n",
    "        self.df = df\n",
    "        if qtable is not None:\n",
    "            self.qtable = qtable\n",
    "        else:\n",
    "            self.qtable = np.zeros((self.state_space, self.action_space))\n",
    "        self.epoches = epoches\n",
    "        self.max_move = max_move\n",
    "        self.eps = eps\n",
    "    \n",
    "    def update_qtable(self, state, action, reward, new_state):\n",
    "        self.qtable[state, action] += self.lr * (reward + self.df*np.max(self.qtable[new_state,:])) - self.qtable[state, action]\n",
    "    \n",
    "    def reset(self):\n",
    "        self.active_state = self.env.reset()[0]\n",
    "    \n",
    "    def select_action(self, state, greedy=False):\n",
    "        # epsilon-greedy algo used for explore vs exploit\n",
    "        action = None\n",
    "        if (np.random.uniform() > self.eps) and (not greedy):\n",
    "            # choose action ranomly\n",
    "            action = np.random.choice(self.action_space)\n",
    "        else:\n",
    "            # act greedly pick the action with max q-value\n",
    "            action = np.argmax(self.qtable[state,:])\n",
    "        return action\n",
    "    \n",
    "    def train(self):\n",
    "        for epoch in range(self.epoches):\n",
    "            self.reset()\n",
    "            for m in range(self.max_move):\n",
    "                action = self.select_action(self.active_state)\n",
    "                next_state, reward, done, _ , _ = self.env.step(action)\n",
    "                self.update_qtable(self.active_state, action, reward, next_state)\n",
    "                self.active_state = next_state\n",
    "                if done:\n",
    "                    break\n",
    "            print(f'epoch {epoch}/{self.epoches}')\n",
    "            \n",
    "    def optimal_drive(self, max_ride=5):\n",
    "        self.reset()\n",
    "        for i in range(max_ride):\n",
    "            for m in range(self.max_move):\n",
    "                action = self.select_action(self.active_state, True)\n",
    "                next_state, reward, done, _ , _ = self.env.step(action)\n",
    "                self.active_state = next_state\n",
    "                self.env.render()\n",
    "                if done:\n",
    "                    break\n",
    "            print(f'{i+1} of {max_ride} ride completed!!')\n",
    "            self.reset()\n",
    "            \n",
    "        self.env.close()\n",
    "        \n",
    "    def random_drive(self, n_move=10):\n",
    "        self.reset()\n",
    "        for i in range(n_move):\n",
    "            print(f'step {i+1}/{n_move}')\n",
    "            ract = self.env.action_space.sample()\n",
    "            self.active_state = self.env.step(ract)\n",
    "            print(self.active_state)\n",
    "            self.env.render()\n",
    "        self.env.close()   \n",
    "        self.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad2ebd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Driver(Drive):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def driving_training(self):\n",
    "        self.train()\n",
    "    \n",
    "    def take_customer_ride(self):\n",
    "        self.env = gym.make('Taxi-v3', render_mode='human').env\n",
    "        self.active_state = self.env.reset()[0]\n",
    "        self.optimal_drive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55458262",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = Driver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94019916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0/1000\n",
      "epoch 1/1000\n",
      "epoch 2/1000\n",
      "epoch 3/1000\n",
      "epoch 4/1000\n",
      "epoch 5/1000\n",
      "epoch 6/1000\n",
      "epoch 7/1000\n",
      "epoch 8/1000\n",
      "epoch 9/1000\n",
      "epoch 10/1000\n",
      ".....\n",
      "epoch 705/1000\n",
      "epoch 706/1000\n",
      "epoch 707/1000\n",
      "epoch 708/1000\n",
      "epoch 709/1000\n",
      "epoch 710/1000\n",
      "epoch 711/1000\n",
      "epoch 712/1000\n",
      "epoch 713/1000\n",
      "epoch 999/1000\n"
     ]
    }
   ],
   "source": [
    "driver.driving_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca07afbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 of 5 ride completed!!\n",
      "2 of 5 ride completed!!\n",
      "3 of 5 ride completed!!\n",
      "4 of 5 ride completed!!\n",
      "5 of 5 ride completed!!\n"
     ]
    }
   ],
   "source": [
    "driver.take_customer_ride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3690a52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python_main] *",
   "language": "python",
   "name": "conda-env-python_main-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
